{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Data Analytics Summer School 3 -- NLP Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preliminaries and Task Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to solve a task called \"stance detection\", which is about classifying the attitude of a sentence towards a concept. Read more about the task here: http://alt.qcri.org/semeval2016/task6/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dear lord thank u for all of ur blessings forgive my sins lord give me strength and energy for this busy day ahead #blessed #hope #SemST Atheism AGAINST\n",
      "Stress on #water resources threatens lives and livelihoods #anthropoceneage #sustainability #SemST Climate Change is a Real Concern FAVOR\n"
     ]
    }
   ],
   "source": [
    "from readwrite.reader import *\n",
    "from readwrite.writer import *\n",
    "\n",
    "fp = \"data/semeval/\"\n",
    "train_path = fp + \"semeval2016-task6-train+dev.txt\"\n",
    "test_path = fp + \"SemEval2016-Task6-subtaskB-testdata-gold.txt\"\n",
    "pred_path = fp + \"SemEval2016-Task6-subtaskB-testdata-pred.txt\"\n",
    "tweets_train, targets_train, labels_train, ids_train = readTweetsOfficial(train_path)\n",
    "tweets_test, targets_test, labels_test, ids_test = readTweetsOfficial(test_path)\n",
    "print(tweets_train[0], targets_train[0], labels_train[0])\n",
    "print(tweets_train[721], targets_train[721], labels_train[721])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we are unsure whether something is halal or haram, we should leave it - this will #safeguard our #deen #rule #SemST\n",
      "Atheism\n",
      "AGAINST\n",
      "{'Atheism', 'Feminist Movement', 'Climate Change is a Real Concern', 'Hillary Clinton', 'Legalization of Abortion'}\n"
     ]
    }
   ],
   "source": [
    "print(tweets_train[5])\n",
    "print(targets_train[5])\n",
    "print(labels_train[5])\n",
    "\n",
    "target_set = set(targets_train)\n",
    "\n",
    "print(target_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each instance consists of a tweet, a target, for which we want to predict a label (\"`FAVOR, AGAINST, NONE`\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second approach uses a pre-implemented classifier and feature extractor from the scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dear lord thank u for all of ur blessings forgive my sins lord give me strength and energy for this busy day ahead #blessed #hope #SemST | Atheism',\n",
       " 'AGAINST')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's first merge the tweets and targets for easier feature extraction\n",
    "tweets_targets_train = [\" | \".join([tweets_train[i], targets_train[i]]) for i in range(len(tweets_train))]\n",
    "tweets_targets_test = [\" | \".join([tweets_test[i], targets_test[i]]) for i in range(len(tweets_test))]\n",
    "tweets_targets_train[0], labels_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now transform the instances into features using sklearn's count vectoriser that assigns an ID to each word, then weighs them based on their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dear': 2144,\n",
       " 'lord': 4879,\n",
       " 'thank': 8002,\n",
       " 'for': 3198,\n",
       " 'all': 447,\n",
       " 'of': 5696,\n",
       " 'ur': 8485,\n",
       " 'blessings': 1082,\n",
       " 'forgive': 3211,\n",
       " 'my': 5413,\n",
       " 'sins': 7365,\n",
       " 'give': 3465,\n",
       " 'me': 5110,\n",
       " 'strength': 7720,\n",
       " 'and': 527,\n",
       " 'energy': 2714,\n",
       " 'this': 8094,\n",
       " 'busy': 1292,\n",
       " 'day': 2126,\n",
       " 'ahead': 408,\n",
       " 'blessed': 1079,\n",
       " 'hope': 3957,\n",
       " 'semst': 7164,\n",
       " 'are': 649,\n",
       " 'the': 8010,\n",
       " 'peacemakers': 5955,\n",
       " 'they': 8080,\n",
       " 'shall': 7234,\n",
       " 'be': 894,\n",
       " 'called': 1325,\n",
       " 'children': 1538,\n",
       " 'god': 3506,\n",
       " 'matthew': 5089,\n",
       " 'scripture': 7096,\n",
       " 'peace': 5952,\n",
       " 'am': 477,\n",
       " 'not': 5602,\n",
       " 'conformed': 1816,\n",
       " 'to': 8179,\n",
       " 'world': 8899,\n",
       " 'transformed': 8258,\n",
       " 'by': 1303,\n",
       " 'renewing': 6707,\n",
       " 'mind': 5222,\n",
       " 'ispeaklife': 4307,\n",
       " '2014': 58,\n",
       " 'salah': 6969,\n",
       " 'should': 7301,\n",
       " 'prayed': 6215,\n",
       " 'with': 8845,\n",
       " 'focus': 3172,\n",
       " 'understanding': 8409,\n",
       " 'allah': 448,\n",
       " 'warns': 8673,\n",
       " 'against': 389,\n",
       " 'lazy': 4664,\n",
       " 'prayers': 6220,\n",
       " 'done': 2455,\n",
       " 'just': 4457,\n",
       " 'show': 7307,\n",
       " 'surah': 7824,\n",
       " 'al': 425,\n",
       " 'maoon': 5029,\n",
       " '107': 9,\n",
       " 'stay': 7637,\n",
       " 'in': 4123,\n",
       " 'your': 8989,\n",
       " 'houses': 3977,\n",
       " 'do': 2419,\n",
       " 'display': 2390,\n",
       " 'yourselves': 8994,\n",
       " 'like': 4792,\n",
       " 'that': 8006,\n",
       " 'times': 8154,\n",
       " 'ignorance': 4072,\n",
       " 'quran': 6494,\n",
       " '33': 100,\n",
       " 'islam': 4301,\n",
       " 'if': 4071,\n",
       " 'we': 8713,\n",
       " 'unsure': 8463,\n",
       " 'whether': 8786,\n",
       " 'something': 7505,\n",
       " 'is': 4296,\n",
       " 'halal': 3682,\n",
       " 'or': 5784,\n",
       " 'haram': 3718,\n",
       " 'leave': 4685,\n",
       " 'it': 4313,\n",
       " 'will': 8822,\n",
       " 'safeguard': 6953,\n",
       " 'our': 5808,\n",
       " 'deen': 2182,\n",
       " 'rule': 6921,\n",
       " 'papa': 5883,\n",
       " 'pray': 6214,\n",
       " 'you': 8984,\n",
       " 'shower': 7309,\n",
       " 'more': 5332,\n",
       " 'patience': 5925,\n",
       " 'worththewait': 8913,\n",
       " 'now': 5628,\n",
       " 'scoc': 7073,\n",
       " 'has': 3737,\n",
       " 'ruled': 6922,\n",
       " 'canadians': 1345,\n",
       " 'have': 3752,\n",
       " 'freedom': 3268,\n",
       " 'from': 3297,\n",
       " 'religion': 6686,\n",
       " 'can': 1342,\n",
       " 'someone': 7503,\n",
       " 'tell': 7955,\n",
       " 'harper': 3729,\n",
       " 'dummy': 2546,\n",
       " 'his': 3894,\n",
       " 'bless': 1078,\n",
       " 'canada': 1343,\n",
       " 'cdnpoli': 1443,\n",
       " 'wow': 8917,\n",
       " 'unsubstantiated': 8462,\n",
       " 'claims': 1610,\n",
       " 'about': 242,\n",
       " 'spooks': 7573,\n",
       " 'remember': 6695,\n",
       " 'whe': 8777,\n",
       " 'said': 6963,\n",
       " 'there': 8064,\n",
       " 'were': 8752,\n",
       " 'gullible': 3638,\n",
       " 'people': 5978,\n",
       " 'jvx242': 4469,\n",
       " 'rt': 6913,\n",
       " 'kind': 4525,\n",
       " 'modesty': 5297,\n",
       " 'too': 8214,\n",
       " 'arrogant': 672,\n",
       " 'Ã®christopher': 9025,\n",
       " 'hitchens': 3904,\n",
       " 'funny': 3344,\n",
       " 'everyone': 2835,\n",
       " 'able': 222,\n",
       " 'believe': 951,\n",
       " 'whatever': 8772,\n",
       " 'want': 8659,\n",
       " 'best': 980,\n",
       " 'those': 8105,\n",
       " 'who': 8799,\n",
       " 'treat': 8277,\n",
       " 'their': 8038,\n",
       " 'women': 8864,\n",
       " 'prophet': 6371,\n",
       " 'mohammad': 5299,\n",
       " 'pbuh': 5950,\n",
       " 'prayerbullets': 6217,\n",
       " 'let': 4722,\n",
       " 'righteousness': 6828,\n",
       " 'joy': 4434,\n",
       " 'kingdom': 4532,\n",
       " 'established': 2798,\n",
       " 'life': 4774,\n",
       " 'rom': 6880,\n",
       " '14': 22,\n",
       " '17': 33,\n",
       " 'stop': 7682,\n",
       " 'hold': 3915,\n",
       " 'allow': 452,\n",
       " 'powerful': 6192,\n",
       " 'time': 8150,\n",
       " 'fight': 3094,\n",
       " 'battle': 875,\n",
       " 'then': 8055,\n",
       " 'win': 8831,\n",
       " 'truth': 8318,\n",
       " 'butgod': 1294,\n",
       " 'faith': 2940,\n",
       " 'sees': 7142,\n",
       " 'invisible': 4271,\n",
       " 'believes': 953,\n",
       " 'incredible': 4148,\n",
       " 'receives': 6601,\n",
       " 'impossible': 4115,\n",
       " 'muhammad': 5391,\n",
       " 'exchange': 2854,\n",
       " 'gift': 3451,\n",
       " 'increase': 4146,\n",
       " 'love': 4895,\n",
       " 'towards': 8238,\n",
       " 'one': 5737,\n",
       " 'another': 570,\n",
       " 'ax2n38': 805,\n",
       " 'halcyondon': 3683,\n",
       " 'tag65': 7886,\n",
       " 'good': 3530,\n",
       " 'luck': 4922,\n",
       " 'separationofchurchandstate': 7190,\n",
       " 'ting': 8160,\n",
       " 'gwg': 3657,\n",
       " 'gfyh': 3439,\n",
       " 'celebrity': 1453,\n",
       " 'atheism': 728,\n",
       " 'beginning': 934,\n",
       " 'irk': 4288,\n",
       " 'initforthemoney': 4192,\n",
       " 'leaving': 4687,\n",
       " 'christianity': 1575,\n",
       " 'enables': 2694,\n",
       " 'once': 5736,\n",
       " 'rejected': 6669,\n",
       " 'freethinker': 3277,\n",
       " 'clear': 1625,\n",
       " 'thoughts': 8112,\n",
       " 'look': 4874,\n",
       " 'up': 8473,\n",
       " 'sky': 7396,\n",
       " 'looking': 4876,\n",
       " 'after': 384,\n",
       " 'heavens': 3791,\n",
       " 'earth': 2577,\n",
       " 'connected': 1826,\n",
       " 'entity': 2745,\n",
       " 'separated': 7188,\n",
       " 'them': 8048,\n",
       " 'havemade': 3753,\n",
       " 'water': 8693,\n",
       " 'every': 2829,\n",
       " 'living': 4842,\n",
       " 'thing': 8084,\n",
       " '21': 65,\n",
       " '30': 94,\n",
       " 'could': 1928,\n",
       " 'please': 6085,\n",
       " 'meeting': 5131,\n",
       " 'continue': 1862,\n",
       " 'grown': 3622,\n",
       " 'ups': 8480,\n",
       " 'only': 5749,\n",
       " 'pop': 6143,\n",
       " 'may': 5100,\n",
       " 'throw': 8128,\n",
       " 'towel': 8239,\n",
       " 'second': 7120,\n",
       " 'half': 3685,\n",
       " 'devil': 2297,\n",
       " 'enemy': 2713,\n",
       " 'battleground': 876,\n",
       " 'he': 3761,\n",
       " 'plays': 6083,\n",
       " 'josh': 4429,\n",
       " 'ricketson': 6817,\n",
       " 'rush': 6930,\n",
       " 'rushswag': 6931,\n",
       " 'odds': 5695,\n",
       " 'already': 466,\n",
       " 'stacked': 7597,\n",
       " 'favor': 3003,\n",
       " 'call': 1323,\n",
       " 'him': 3887,\n",
       " 'savior': 7026,\n",
       " 'when': 8781,\n",
       " 'comes': 1729,\n",
       " 'scientific': 7069,\n",
       " 'discoveries': 2364,\n",
       " 'religious': 6689,\n",
       " 'bullshit': 1267,\n",
       " 'until': 8466,\n",
       " 'texts': 7997,\n",
       " 'knew': 4548,\n",
       " 'at': 725,\n",
       " 'others': 5806,\n",
       " 'envy': 2753,\n",
       " 'on': 5734,\n",
       " 'what': 8768,\n",
       " 'calling': 1326,\n",
       " 'become': 916,\n",
       " 'dream': 2494,\n",
       " 'sized': 7382,\n",
       " 'dreams': 2497,\n",
       " 'purpose': 6439,\n",
       " 'wealthy': 8718,\n",
       " 'would': 8915,\n",
       " 'no': 5558,\n",
       " 'becoming': 918,\n",
       " 'don': 2450,\n",
       " 'feel': 3030,\n",
       " 'need': 5492,\n",
       " 'desire': 2271,\n",
       " 'cause': 1431,\n",
       " 'making': 4990,\n",
       " 'definite': 2201,\n",
       " 'marks': 5050,\n",
       " 'never': 5516,\n",
       " 'think': 8087,\n",
       " 'holy': 3926,\n",
       " 'mary': 5065,\n",
       " 'mother': 5349,\n",
       " 'us': 8493,\n",
       " 'sinners': 7362,\n",
       " 'hour': 3971,\n",
       " 'death': 2145,\n",
       " 'amen': 494,\n",
       " 'rosary': 6893,\n",
       " 'teamjesus': 7930,\n",
       " 'see': 7132,\n",
       " 'natural': 5468,\n",
       " 'getting': 3436,\n",
       " 'ready': 6575,\n",
       " 'release': 6681,\n",
       " 'supernatual': 7805,\n",
       " 'religions': 6688,\n",
       " 'stopped': 7694,\n",
       " 'being': 943,\n",
       " 'credible': 1972,\n",
       " 'minute': 5238,\n",
       " 'first': 3129,\n",
       " 'dinosaur': 2336,\n",
       " 'fossil': 3227,\n",
       " 'was': 8680,\n",
       " 'found': 3230,\n",
       " 'faithreei': 2944,\n",
       " 'dogs': 2434,\n",
       " 'carries': 1398,\n",
       " 'baby': 818,\n",
       " 'home': 3931,\n",
       " 'dump': 2547,\n",
       " 'photo': 6028,\n",
       " 'hero': 3822,\n",
       " 'absence': 248,\n",
       " 'nothing': 5615,\n",
       " 'than': 8001,\n",
       " 'an': 518,\n",
       " 'accident': 272,\n",
       " 're': 6566,\n",
       " 'arrangement': 666,\n",
       " 'molecules': 5302,\n",
       " 'bible': 1010,\n",
       " 'better': 992,\n",
       " 'go': 3502,\n",
       " 'get': 3433,\n",
       " 'ball': 838,\n",
       " 'save': 7014,\n",
       " 'yours': 8992,\n",
       " 'shepherd': 7265,\n",
       " 'take': 7888,\n",
       " 'care': 1384,\n",
       " 'forever': 3208,\n",
       " 'psalm': 6418,\n",
       " '28': 81,\n",
       " 'gnt': 3501,\n",
       " 'question': 6472,\n",
       " 'answe': 571,\n",
       " 'jeremysumpter': 4369,\n",
       " 'such': 7770,\n",
       " 'beautiful': 908,\n",
       " 'sunday': 7795,\n",
       " 'truly': 8311,\n",
       " 'church': 1589,\n",
       " 'happines': 3711,\n",
       " 'remove': 6701,\n",
       " 'bitterness': 1058,\n",
       " 'heart': 3779,\n",
       " 'sometimes': 7506,\n",
       " 'protecting': 6384,\n",
       " 'things': 8085,\n",
       " 'way': 8705,\n",
       " 'trust': 8314,\n",
       " 'wisdom': 8840,\n",
       " 'perseverance': 6003,\n",
       " 'hardwork': 3727,\n",
       " 'separates': 7189,\n",
       " 'dreamers': 2496,\n",
       " 'achievers': 290,\n",
       " 'godfirst': 3508,\n",
       " 'actorslife': 308,\n",
       " 'dancer': 2078,\n",
       " 'letswork': 4730,\n",
       " 'vision': 8598,\n",
       " 'work': 8892,\n",
       " 'comprehensive': 1776,\n",
       " 'selective': 7152,\n",
       " 'ask': 690,\n",
       " 'everything': 2836,\n",
       " 'lovemyjesus': 4903,\n",
       " 'holycrapthatsgoodnews': 3928,\n",
       " 'shows': 7313,\n",
       " 'mercy': 5166,\n",
       " 'matter': 5087,\n",
       " 'darkness': 2096,\n",
       " 've': 8546,\n",
       " 'been': 923,\n",
       " 'll': 4845,\n",
       " 'answering': 575,\n",
       " 'questions': 6474,\n",
       " 'today': 8184,\n",
       " 'reddit': 6619,\n",
       " 'askanatheistday': 692,\n",
       " '5pm': 145,\n",
       " 'est': 2796,\n",
       " 'ama': 478,\n",
       " 'atheist': 729,\n",
       " 'askanatheist': 691,\n",
       " 'particular': 5904,\n",
       " 'culture': 2030,\n",
       " 'doing': 2438,\n",
       " 'ed': 2602,\n",
       " 'welch': 8743,\n",
       " 'face': 2914,\n",
       " 'end': 2701,\n",
       " 'know': 4554,\n",
       " 'okay': 5720,\n",
       " 'because': 914,\n",
       " 'maker': 4986,\n",
       " 'happynote': 3717,\n",
       " 'free': 3265,\n",
       " 'literature': 4830,\n",
       " 'pass': 5911,\n",
       " 'out': 5812,\n",
       " 'upcoming': 8474,\n",
       " 'protest': 6391,\n",
       " 'planning': 6068,\n",
       " 'ffrf': 3087,\n",
       " 'evidence': 2840,\n",
       " 'based': 865,\n",
       " 'thought': 8109,\n",
       " 'works': 8898,\n",
       " 'superstition': 7807,\n",
       " 'these': 8073,\n",
       " 'studies': 7743,\n",
       " 'part': 5900,\n",
       " 'unt': 8464,\n",
       " 'makes': 4987,\n",
       " 'kinda': 4526,\n",
       " 'wanna': 8658,\n",
       " 'seminary': 7163,\n",
       " 'school': 7061,\n",
       " 'meangreen': 5113,\n",
       " 'gospel': 3545,\n",
       " 'musical_seizure': 5405,\n",
       " 'very': 8557,\n",
       " 'cool': 1896,\n",
       " 'but': 1293,\n",
       " 'any': 597,\n",
       " 'implying': 4110,\n",
       " 'souls': 7529,\n",
       " 'so': 7458,\n",
       " 'creator': 1969,\n",
       " 'how': 3979,\n",
       " 'hard': 3725,\n",
       " 'tried': 8290,\n",
       " 'disconnect': 2359,\n",
       " 'heaven': 3790,\n",
       " 'created': 1962,\n",
       " 'might': 5205,\n",
       " 'indeed': 4156,\n",
       " 'its': 4320,\n",
       " 'expander': 2870,\n",
       " '51': 137,\n",
       " '47': 123,\n",
       " 'worst': 8910,\n",
       " 'far': 2971,\n",
       " 'here': 3819,\n",
       " 'setting': 7210,\n",
       " 'nan': 5446,\n",
       " 'rest': 6770,\n",
       " 'even': 2822,\n",
       " 'as': 680,\n",
       " 'physicist': 6034,\n",
       " 'make': 4984,\n",
       " 'wonder': 8877,\n",
       " 'shout': 7305,\n",
       " 'almighty': 458,\n",
       " 'two': 8360,\n",
       " 'without': 8848,\n",
       " 'proof': 6365,\n",
       " 'atheistrepublic': 732,\n",
       " 'where': 8784,\n",
       " 'does': 2429,\n",
       " 'morality': 5327,\n",
       " 'come': 1725,\n",
       " 'innate': 4199,\n",
       " 'sense': 7177,\n",
       " 'response': 6765,\n",
       " 'suffering': 7780,\n",
       " 'atheists': 734,\n",
       " 'humanrights': 4009,\n",
       " 'going': 3519,\n",
       " 'thru': 8131,\n",
       " 'assure': 720,\n",
       " 'somewhere': 7507,\n",
       " 'somebody': 7500,\n",
       " '10x': 11,\n",
       " 'worse': 8908,\n",
       " 'bethankful': 985,\n",
       " 'believers': 952,\n",
       " 'prove': 6404,\n",
       " 'book': 1138,\n",
       " 'must': 5410,\n",
       " 'read': 6571,\n",
       " 'regards': 6652,\n",
       " 'spirit': 7565,\n",
       " 'wherever': 8785,\n",
       " 'corinthians': 1908,\n",
       " 'nlt': 5556,\n",
       " 'true': 8309,\n",
       " 'community': 1754,\n",
       " 'disagree': 2347,\n",
       " 'still': 7670,\n",
       " 'roadtolife': 6854,\n",
       " 'education': 2607,\n",
       " 'weapon': 8719,\n",
       " 'obstacle': 5680,\n",
       " 'sahd': 6960,\n",
       " 'freethinkers': 3278,\n",
       " 'homeschooling': 3936,\n",
       " 'watched': 8691,\n",
       " 'scfeatured': 7057,\n",
       " 'segment': 7145,\n",
       " 'manny': 5017,\n",
       " 'pacquiao': 5852,\n",
       " 'wasn': 8686,\n",
       " 'teampacquiao': 7934,\n",
       " 'respect': 6762,\n",
       " 'around': 665,\n",
       " 'find': 3111,\n",
       " 'fear': 3014,\n",
       " 'father': 2995,\n",
       " 'togodbetheglory': 8192,\n",
       " 'plan': 6063,\n",
       " 'gotta': 3552,\n",
       " 'willing': 8826,\n",
       " 'seek': 7137,\n",
       " 'gives': 3468,\n",
       " 'anything': 602,\n",
       " 'handle': 3691,\n",
       " 'either': 2625,\n",
       " 'victory': 8571,\n",
       " 'lesson': 4721,\n",
       " 'amazing': 483,\n",
       " 'inspiration': 4215,\n",
       " 'run': 6925,\n",
       " 'till': 8148,\n",
       " 'king': 4531,\n",
       " 'wouldn': 8916,\n",
       " 'invest': 4267,\n",
       " 'anointing': 568,\n",
       " 'gotfaith': 3551,\n",
       " 'sayyes': 7035,\n",
       " 'latikia': 4635,\n",
       " 'seangillies': 7109,\n",
       " 'yeah': 8959,\n",
       " 'right': 6826,\n",
       " 'lol': 4865,\n",
       " 'wink': 8834,\n",
       " 'nudge': 5636,\n",
       " 'greatest': 3589,\n",
       " 'playing': 6081,\n",
       " 'along': 462,\n",
       " 'religiondoesharm': 6687,\n",
       " 'given': 3466,\n",
       " 'timidity': 8157,\n",
       " 'power': 6191,\n",
       " 'self': 7153,\n",
       " 'discipline': 2356,\n",
       " 'timothy': 8158,\n",
       " 'fearless': 3017,\n",
       " 'conqueror': 1831,\n",
       " 'sexiest': 7218,\n",
       " 'carry': 1399,\n",
       " 'accessory': 271,\n",
       " 'christian': 1574,\n",
       " 'scientists': 7071,\n",
       " 'say': 7030,\n",
       " 'iron': 4289,\n",
       " 'sorry': 7520,\n",
       " '57': 141,\n",
       " '25': 75,\n",
       " 'outran': 5820,\n",
       " '1400': 24,\n",
       " 'years': 8962,\n",
       " 'dw_english': 2557,\n",
       " 'prevails': 6270,\n",
       " 'yet': 8976,\n",
       " 'sorrowful': 7519,\n",
       " 'reality': 6585,\n",
       " 'accuser': 285,\n",
       " 'accuse': 283,\n",
       " 'washed': 8682,\n",
       " 'cleansed': 1623,\n",
       " 'blood': 1096,\n",
       " 'lamb': 4612,\n",
       " 'rev': 6795,\n",
       " 'india': 4159,\n",
       " 'urges': 8491,\n",
       " 'temples': 7962,\n",
       " 'bolster': 1130,\n",
       " 'economy': 2599,\n",
       " 'gold': 3520,\n",
       " 'worldnews': 8902,\n",
       " 'economics': 2598,\n",
       " 'commodities': 1746,\n",
       " 'sex': 7215,\n",
       " 'music': 5404,\n",
       " 'sting': 7675,\n",
       " 'richarddawkins': 6816,\n",
       " 'likely': 4795,\n",
       " 'real': 6580,\n",
       " 'bigfoot': 1015,\n",
       " 'loch': 4855,\n",
       " 'ness': 5510,\n",
       " 'monster': 5320,\n",
       " 'alot': 463,\n",
       " 'angry': 542,\n",
       " 'steadfast': 7640,\n",
       " 'ponder': 6135,\n",
       " 'upon': 8479,\n",
       " 'qur': 6493,\n",
       " 'means': 5117,\n",
       " 'acquire': 295,\n",
       " 'steadfastness': 7641,\n",
       " 'rosaryrevival': 6894,\n",
       " 'dhiggins63': 2301,\n",
       " 'fiction': 3090,\n",
       " 'incapable': 4128,\n",
       " 'killing': 4519,\n",
       " 'pvtfraser': 6458,\n",
       " 'breaking911': 1192,\n",
       " 'police': 6111,\n",
       " 'hooligans': 3955,\n",
       " 'challenge': 1471,\n",
       " 'frustration': 3308,\n",
       " 'criminals': 1982,\n",
       " 'black': 1061,\n",
       " 'white': 8794,\n",
       " 'station': 7632,\n",
       " 'destination': 2277,\n",
       " 'cover': 1945,\n",
       " 'girl': 3458,\n",
       " 'lacks': 4596,\n",
       " 'deficiencies': 2196,\n",
       " 'foundation': 3232,\n",
       " 'blend': 1076,\n",
       " 'perfectly': 5990,\n",
       " 'alpharomeo223': 465,\n",
       " 'quite': 6483,\n",
       " 'mistaken': 5273,\n",
       " 'arrive': 670,\n",
       " 'constant': 1850,\n",
       " 'awe': 795,\n",
       " 'much': 5388,\n",
       " 'loves': 4907,\n",
       " 'family': 2961,\n",
       " 'urs': 8492,\n",
       " 'crucified': 2006,\n",
       " 'christ': 1573,\n",
       " 'longer': 4873,\n",
       " 'live': 4835,\n",
       " 'lives': 4840,\n",
       " 'galatians': 3366,\n",
       " '20': 52,\n",
       " 'holybible': 3927,\n",
       " 'between': 993,\n",
       " 'mere': 5167,\n",
       " 'play': 6077,\n",
       " '44': 119,\n",
       " '38': 106,\n",
       " 'athiest': 735,\n",
       " 'posturing': 6183,\n",
       " 'pretending': 6264,\n",
       " 'pontificating': 6137,\n",
       " 'baltimore': 842,\n",
       " 'baltimoreriots': 843,\n",
       " 'jesus': 4377,\n",
       " 'didn': 2314,\n",
       " 'bring': 1220,\n",
       " 'appreciate': 633,\n",
       " 'waking': 8648,\n",
       " 'diz': 2411,\n",
       " 'giving': 3469,\n",
       " 'brilliant': 1219,\n",
       " 'ideas': 4056,\n",
       " 'grow': 3619,\n",
       " 'hustle': 4027,\n",
       " 'kip': 4535,\n",
       " 'laughing': 4644,\n",
       " 'shed': 7259,\n",
       " 'tears': 7938,\n",
       " 'bt': 1250,\n",
       " 'gonna': 3529,\n",
       " 'hpn': 3985,\n",
       " 'childofgod': 1537,\n",
       " 'everywhere': 2838,\n",
       " 'thee': 8026,\n",
       " 'lil': 4798,\n",
       " 'slapped': 7401,\n",
       " 'helives': 3806,\n",
       " 'potter': 6186,\n",
       " 'iamtheclay': 4038,\n",
       " 'iamisthepotter': 4037,\n",
       " 'belief': 949,\n",
       " 'many': 5027,\n",
       " 'doctrines': 2426,\n",
       " 'christians': 1578,\n",
       " 'theology': 8058,\n",
       " 'sahaba': 6959,\n",
       " 'sign': 7330,\n",
       " 'hating': 3749,\n",
       " 'hypocrisy': 4029,\n",
       " '10': 3,\n",
       " 'feet': 3036,\n",
       " 'planted': 6071,\n",
       " 'ground': 3614,\n",
       " 'angel': 537,\n",
       " 'angels': 539,\n",
       " 'sing': 7355,\n",
       " 'innocent': 4201,\n",
       " 'maryjaneveloso': 5067,\n",
       " 'gaps': 3379,\n",
       " 'next': 5532,\n",
       " 'yourself': 8993,\n",
       " 'doesn': 2430,\n",
       " 'add': 327,\n",
       " 'kinds': 4530,\n",
       " 'magic': 4968,\n",
       " 'miracles': 5242,\n",
       " 'myth': 5424,\n",
       " 'oh': 5712,\n",
       " 'rational': 6560,\n",
       " 'esteem': 2800,\n",
       " 'won': 8876,\n",
       " 'abandon': 205,\n",
       " 'scott': 7078,\n",
       " 'sauls': 7011,\n",
       " 'evangelistmatt': 2818,\n",
       " 'why': 8808,\n",
       " 'providing': 6411,\n",
       " 'concise': 1790,\n",
       " 'answers': 576,\n",
       " 'always': 474,\n",
       " 'listening': 4824,\n",
       " 'maybe': 5102,\n",
       " 'ways': 8707,\n",
       " 'had': 3668,\n",
       " 'hoped': 3959,\n",
       " 'knows': 4558,\n",
       " 'prayerworks': 6222,\n",
       " 'framers': 3247,\n",
       " 'constitution': 1853,\n",
       " 'meant': 5118,\n",
       " 'billy': 1031,\n",
       " 'graham': 3571,\n",
       " 'quote': 6489,\n",
       " 'neiltyson': 5505,\n",
       " 'afraid': 380,\n",
       " 'wrong': 8925,\n",
       " 'stronger': 7731,\n",
       " 'avoid': 787,\n",
       " 'facing': 2921,\n",
       " 'facts': 2925,\n",
       " 'compounds': 1775,\n",
       " 'ago': 402,\n",
       " 'son': 7508,\n",
       " 'taken': 7893,\n",
       " 'fuck': 3313,\n",
       " 'tree': 8283,\n",
       " 'known': 4557,\n",
       " 'own': 5843,\n",
       " 'fruit': 3304,\n",
       " 'thorns': 8104,\n",
       " 'men': 5149,\n",
       " 'gather': 3385,\n",
       " 'figs': 3097,\n",
       " 'nor': 5588,\n",
       " 'bramble': 1177,\n",
       " 'bush': 1286,\n",
       " 'grapes': 3579,\n",
       " 'luke': 4927,\n",
       " 'imagine': 4090,\n",
       " 'credit': 1973,\n",
       " 'did': 2313,\n",
       " 'well': 8746,\n",
       " 'got': 3549,\n",
       " 'blame': 1070,\n",
       " 'laur_guuurl': 4647,\n",
       " 'alittle': 445,\n",
       " 'cup': 2036,\n",
       " 'yougotit': 8985,\n",
       " 'cares': 1389,\n",
       " 'concerns': 1788,\n",
       " 'talk': 7896,\n",
       " 'necessity': 5490,\n",
       " 'innovation': 4203,\n",
       " 'complete': 1769,\n",
       " 'city': 1604,\n",
       " 'clarity': 1614,\n",
       " 'resolution': 6759,\n",
       " 'bind': 1033,\n",
       " 'rebuke': 6598,\n",
       " 'demons': 2244,\n",
       " 'jihad': 4388,\n",
       " 'name': 5443,\n",
       " 'denied': 2250,\n",
       " 'soul': 7528,\n",
       " 'made': 4953,\n",
       " 'literally': 4828,\n",
       " 'ever': 2827,\n",
       " 'answer': 572,\n",
       " 'keep': 4490,\n",
       " 'curiosity': 2038,\n",
       " 'alive': 446,\n",
       " 'nagging': 5434,\n",
       " 'doubt': 2475,\n",
       " 'having': 3756,\n",
       " 'gods': 3513,\n",
       " 'testing': 7985,\n",
       " 'intellect': 4237,\n",
       " 'trying': 8325,\n",
       " 'beliefs': 950,\n",
       " 'lk': 4844,\n",
       " '37': 105,\n",
       " 'kjv': 4542,\n",
       " 'judge': 4441,\n",
       " 'ye': 8957,\n",
       " 'judged': 4442,\n",
       " 'condemn': 1793,\n",
       " 'condemned': 1794,\n",
       " 'eternal': 2807,\n",
       " 'whom': 8804,\n",
       " 'sent': 7181,\n",
       " 'john': 4409,\n",
       " 'word': 8886,\n",
       " 'also': 468,\n",
       " 'mormon': 5334,\n",
       " 'joseph': 4428,\n",
       " 'smith': 7443,\n",
       " 'discouraged': 2361,\n",
       " 'dont': 2462,\n",
       " 'happen': 3706,\n",
       " 'planned': 6066,\n",
       " 'store': 7698,\n",
       " 'pressing': 6260,\n",
       " 'forward': 3226,\n",
       " 'teamperserverance': 7935,\n",
       " 'tonymiano': 8213,\n",
       " 'thecorruptorr': 8022,\n",
       " 'scam': 7042,\n",
       " 'money': 5313,\n",
       " 'selling': 7157,\n",
       " 'words': 8889,\n",
       " 'claim': 1609,\n",
       " 'none': 5581,\n",
       " 'interesting': 4245,\n",
       " 'dangerous': 2084,\n",
       " 'existence': 2867,\n",
       " 'republic': 6742,\n",
       " 'introduce': 4259,\n",
       " 'into': 4257,\n",
       " 'politics': 6127,\n",
       " 'robert': 6859,\n",
       " 'green': 3594,\n",
       " 'ingersoll': 4186,\n",
       " 'became': 913,\n",
       " 'man': 5002,\n",
       " 'athanasius': 726,\n",
       " 'trebor12566': 8282,\n",
       " 'wish': 8843,\n",
       " 'eliminate': 2640,\n",
       " 'new': 5520,\n",
       " 'verse': 8554,\n",
       " 'hears': 3778,\n",
       " 'rejects': 6670,\n",
       " '16': 31,\n",
       " 'bornagain': 1146,\n",
       " 'teamcogic': 7929,\n",
       " 'holyspirit': 3930,\n",
       " 'miraculous': 5243,\n",
       " 'logic': 4860,\n",
       " 'reason': 6591,\n",
       " 'science': 7067,\n",
       " 'faithful': 2942,\n",
       " 'learn': 4680,\n",
       " 'uncertainty': 8399,\n",
       " 'mystery': 5423,\n",
       " 'walking': 8653,\n",
       " 'toward': 8237,\n",
       " 'presence': 6250,\n",
       " 'step': 7647,\n",
       " 'cannot': 1357,\n",
       " 'control': 1875,\n",
       " 'knowing': 4555,\n",
       " 'whoever': 8800,\n",
       " 'younger': 8988,\n",
       " 'ones': 5740,\n",
       " 'elders': 2629,\n",
       " 'nation': 5463,\n",
       " 'stand': 7607,\n",
       " 'equality': 2762,\n",
       " 'fairness': 2938,\n",
       " 'freedomofspeech': 3272,\n",
       " 'fool': 3193,\n",
       " 'dies': 2320,\n",
       " 'mouth': 5358,\n",
       " 'feed': 3028,\n",
       " 'prov': 6403,\n",
       " 'righteous': 6827,\n",
       " 'practice': 6206,\n",
       " 'image': 4087,\n",
       " 'chip': 1547,\n",
       " 'ingram': 4188,\n",
       " 'fb': 3008,\n",
       " 'north': 5596,\n",
       " 'missions': 5267,\n",
       " 'followdms': 3180,\n",
       " 'knock': 4550,\n",
       " 'door': 2470,\n",
       " 'opened': 5758,\n",
       " 'matt': 5086,\n",
       " 'davidpakmanshow': 2124,\n",
       " 'liberalbias': 4752,\n",
       " 'hell': 3807,\n",
       " 'existed': 2866,\n",
       " 'line': 4809,\n",
       " 'transcends': 8255,\n",
       " 'rather': 6558,\n",
       " 'godsnotdead': 3514,\n",
       " 'sikhism': 7336,\n",
       " 'finish': 3118,\n",
       " 'saimarani13': 6965,\n",
       " 'beinghu62727983': 946,\n",
       " 'maheshhindu': 4974,\n",
       " 'po_st': 6099,\n",
       " 'swamy39': 7849,\n",
       " 'cum': 2033,\n",
       " 'peter': 6013,\n",
       " 'theists': 8040,\n",
       " 'big': 1014,\n",
       " 'mountain': 5357,\n",
       " 'fucking': 3318,\n",
       " 'hear': 3775,\n",
       " 'again': 388,\n",
       " 'government': 3557,\n",
       " 'spying': 7586,\n",
       " 'tcot': 7921,\n",
       " 'p2': 5850,\n",
       " 'equal': 2760,\n",
       " 'morally': 5328,\n",
       " 'superior': 7804,\n",
       " 'fuckfeminism': 3317,\n",
       " 'equalityforall': 2764,\n",
       " 'ensures': 2735,\n",
       " 'justice': 4459,\n",
       " 'orphans': 5800,\n",
       " 'widows': 8815,\n",
       " 'strangers': 7710,\n",
       " 'food': 3191,\n",
       " 'clothing': 1675,\n",
       " 'deut': 2289,\n",
       " '18': 37,\n",
       " 'goldanuli': 3521,\n",
       " 'isn': 4305,\n",
       " 'interested': 4244,\n",
       " 'ali': 441,\n",
       " 'amin': 503,\n",
       " 'lebanon': 4688,\n",
       " 'shia': 7272,\n",
       " 'leader': 4668,\n",
       " '70s': 156,\n",
       " 'iran': 4280,\n",
       " 'regime': 6656,\n",
       " 'conduct': 1800,\n",
       " 'turn': 8339,\n",
       " 'situation': 7378,\n",
       " 'ha': 3662,\n",
       " 'varun': 8537,\n",
       " 'gandhi': 3377,\n",
       " 'great': 3586,\n",
       " 'grand': 3573,\n",
       " 'nehru': 5502,\n",
       " 'hindu': 3890,\n",
       " 'brahmin': 1172,\n",
       " 'ancestry': 524,\n",
       " 'chameleon': 1473,\n",
       " 'regularly': 6662,\n",
       " 'base': 864,\n",
       " 'superstitions': 7808,\n",
       " 'skepticpedi': 7387,\n",
       " 'performing': 5993,\n",
       " 'medicine': 5129,\n",
       " 'reiterate': 6667,\n",
       " 'expect': 2872,\n",
       " 'walk': 8650,\n",
       " 'supernatural': 7806,\n",
       " 'lethimin': 4726,\n",
       " 'dontdoministryalone': 2463,\n",
       " 'waterwalker': 8699,\n",
       " 'boom': 1140,\n",
       " 'alwaysoptimistic': 475,\n",
       " 'zubair': 9024,\n",
       " 'ibn': 4043,\n",
       " 'awwam': 803,\n",
       " 'accepted': 268,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv.fit(tweets_train)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 408)\t1\n",
      "  (0, 447)\t1\n",
      "  (0, 527)\t1\n",
      "  (0, 728)\t1\n",
      "  (0, 1079)\t1\n",
      "  (0, 1082)\t1\n",
      "  (0, 1292)\t1\n",
      "  (0, 2126)\t1\n",
      "  (0, 2144)\t1\n",
      "  (0, 2714)\t1\n",
      "  (0, 3198)\t2\n",
      "  (0, 3211)\t1\n",
      "  (0, 3465)\t1\n",
      "  (0, 3957)\t1\n",
      "  (0, 4879)\t2\n",
      "  (0, 5110)\t1\n",
      "  (0, 5413)\t1\n",
      "  (0, 5696)\t1\n",
      "  (0, 7164)\t1\n",
      "  (0, 7365)\t1\n",
      "  (0, 7720)\t1\n",
      "  (0, 8002)\t1\n",
      "  (0, 8094)\t1\n",
      "  (0, 8485)\t1\n"
     ]
    }
   ],
   "source": [
    "features_train = cv.transform(tweets_targets_train)\n",
    "features_test = cv.transform(tweets_targets_test)\n",
    "print(features_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define and train a simple logistic regression model with L2 regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s(f(x), g(x)) + loss function handled by this model\n",
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NONE'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(features_test)\n",
    "predictions[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: inspect the predictions and check for which examples incorrect vs. correct features are made. Inspect which features are good vs. bad predictors of the test set instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well we did overall and compute evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    AGAINST       0.75      0.01      0.02       299\n",
      "      FAVOR       0.00      0.00      0.00       148\n",
      "       NONE       0.37      1.00      0.54       260\n",
      "\n",
      "avg / total       0.45      0.37      0.21       707\n",
      "\n",
      "{'FAVOR', 'AGAINST', 'NONE'}\n",
      "{'AGAINST', 'NONE'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathias\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(labels_test, predictions))\n",
    "print(set(labels_test))\n",
    "print(set(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at which labels were often confused with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   0 296]\n",
      " [  0   0 148]\n",
      " [  1   0 259]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: try to understand the confusion matrix and think about what would cause the results you observe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our third approach is to use word embeddings, which are trained using a simple feed-forward neural network. Word embeddings are commonly used in NLP, so there are many ready-made software packages, the most common one of which is word2vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While scikit-learn did all the preprocessing and feature extraction for us, we now have to put in a little bit more work for this.\n",
    "First, we tokenise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ex3_word2vec.tokenize_tweets import tokenise_tweets\n",
    "#tweet_tokens = tokenise_tweets(tweets_train)\n",
    "#target_tokens = tokenise_tweets(targets_train)\n",
    "#tweet_tokens_test = tokenise_tweets(tweets_test)\n",
    "#target_tokens_test = tokenise_tweets(targets_test)\n",
    "tweets_targets_train_tokens = tokenise_tweets(tweets_targets_train)\n",
    "tweets_targets_test_tokens = tokenise_tweets(tweets_targets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to convert labels to indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2Indeces(labels):\n",
    "    labels_ret = []\n",
    "    for i, lab in enumerate(labels):\n",
    "        if lab == 'NONE':\n",
    "            labels_ret.append(0)\n",
    "        elif lab == 'FAVOR':\n",
    "            labels_ret.append(2)\n",
    "        elif lab == 'AGAINST':\n",
    "            labels_ret.append(1)\n",
    "    return labels_ret\n",
    "\n",
    "labels_train_idx = label2Indeces(labels_train)\n",
    "labels_test_idx = label2Indeces(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to train a word2vec model. We first turn on logging to monitor the training process and set the word2vec model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# set params\n",
    "num_features = 100    # Word vector dimensionality\n",
    "min_word_count = 2   # Minimum word count\n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "trainalgo = 1 # cbow: 0 / skip-gram: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import the word2vec `gensim` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathias\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2018-11-29 15:39:02,080 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the package is not found, uncomment and run the line below to install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:39:04,965 : INFO : collecting all words and their counts\n",
      "2018-11-29 15:39:04,968 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-11-29 15:39:05,059 : INFO : collected 9910 word types from a corpus of 107326 raw words and 5628 sentences\n",
      "2018-11-29 15:39:05,063 : INFO : Loading a fresh vocabulary\n",
      "2018-11-29 15:39:05,142 : INFO : effective_min_count=2 retains 9910 unique words (100% of original 9910, drops 0)\n",
      "2018-11-29 15:39:05,145 : INFO : effective_min_count=2 leaves 107326 word corpus (100% of original 107326, drops 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:39:05,334 : INFO : deleting the raw counts dictionary of 9910 items\n",
      "2018-11-29 15:39:05,337 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2018-11-29 15:39:05,338 : INFO : downsampling leaves estimated 81982 word corpus (76.4% of prior 107326)\n",
      "2018-11-29 15:39:05,411 : INFO : estimated required memory for 9910 words and 100 dimensions: 12883000 bytes\n",
      "2018-11-29 15:39:05,412 : INFO : resetting layer weights\n",
      "2018-11-29 15:39:05,827 : INFO : training model with 4 workers on 9910 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-11-29 15:39:06,393 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 15:39:06,541 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 15:39:06,559 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 15:39:06,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 15:39:06,574 : INFO : EPOCH - 1 : training on 107326 raw words (82006 effective words) took 0.7s, 112577 effective words/s\n",
      "2018-11-29 15:39:07,180 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 15:39:07,352 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 15:39:07,397 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 15:39:07,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 15:39:07,424 : INFO : EPOCH - 2 : training on 107326 raw words (81882 effective words) took 0.8s, 100809 effective words/s\n",
      "2018-11-29 15:39:08,052 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 15:39:08,209 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 15:39:08,221 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 15:39:08,255 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 15:39:08,257 : INFO : EPOCH - 3 : training on 107326 raw words (82059 effective words) took 0.8s, 101312 effective words/s\n",
      "2018-11-29 15:39:08,911 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 15:39:09,054 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 15:39:09,059 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 15:39:09,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 15:39:09,084 : INFO : EPOCH - 4 : training on 107326 raw words (81858 effective words) took 0.8s, 103715 effective words/s\n",
      "2018-11-29 15:39:09,672 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 15:39:09,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 15:39:09,864 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 15:39:09,870 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 15:39:09,872 : INFO : EPOCH - 5 : training on 107326 raw words (82035 effective words) took 0.8s, 108158 effective words/s\n",
      "2018-11-29 15:39:09,875 : INFO : training on a 536630 raw words (409840 effective words) took 4.0s, 101314 effective words/s\n",
      "2018-11-29 15:39:09,877 : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-11-29 15:39:10,212 : INFO : saving Word2Vec object under models/skip_nostop_sing_100features_5minwords_10context, separately None\n",
      "2018-11-29 15:39:10,215 : INFO : not storing attribute vectors_norm\n",
      "2018-11-29 15:39:10,217 : INFO : not storing attribute cum_table\n",
      "2018-11-29 15:39:10,494 : INFO : saved models/skip_nostop_sing_100features_5minwords_10context\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(tweets_targets_train_tokens, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling, sg = trainalgo)\n",
    "\n",
    "# add for memory efficiency\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# save the model\n",
    "model.save(\"models/skip_nostop_sing_100features_5minwords_10context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can example what the word2vec model has learned.\n",
    "\n",
    "Exercise: play around with the three functions below by inputting diifferent words. What do you observe? \n",
    "Hint: you can access the model's vocabulary with \"`model.wv.vocab`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find  20  terms most similar to  #abortion ...\n",
      "('rich', 0.990666389465332)\n",
      "('personally', 0.9897016882896423)\n",
      "('#thingsyoudontsayasapolitician', 0.9896957874298096)\n",
      "('beg', 0.9891961812973022)\n",
      "('quit', 0.9891592860221863)\n",
      "('atheist', 0.9889217615127563)\n",
      "('busy', 0.9888014197349548)\n",
      "('hurt', 0.9883986711502075)\n",
      "('dad', 0.9882718920707703)\n",
      "('refuse', 0.988067626953125)\n",
      "('taken', 0.9879710674285889)\n",
      "('obviously', 0.9875509738922119)\n",
      "('dick', 0.987427830696106)\n",
      "('scared', 0.9870878458023071)\n",
      "('boobs', 0.9863909482955933)\n",
      "('troll', 0.9859837293624878)\n",
      "('tiny', 0.9858169555664062)\n",
      "('asking', 0.9855866432189941)\n",
      "('living', 0.9850107431411743)\n",
      "('married', 0.9849096536636353)\n",
      "\n",
      "\n",
      "Computing similarity between  trump  and  conservative ...\n",
      "0.91756403 \n",
      "\n",
      "Finding terms containing  trump ...\n",
      "@realdonaldtrump\n",
      "trump\n",
      "#donaldtrump\n",
      "@strumpetcity\n",
      "#trump\n",
      "#trump2016\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathias\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# if needed, load a word2vec model\n",
    "# model = word2vec.Word2Vec.load(modelname)\n",
    "\n",
    "# find most similar n words to given word\n",
    "def applyWord2VecMostSimilar(model, word=\"#abortion\", top=20):\n",
    "    print(\"Find \", top, \" terms most similar to \", word, \"...\")\n",
    "    for res in model.wv.most_similar(word, topn=top):\n",
    "        print(res)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# determine similarity between words\n",
    "def applyWord2VecSimilarityBetweenWords(model, w1=\"trump\", w2=\"conservative\"):\n",
    "    print(\"Computing similarity between \", w1, \" and \", w2, \"...\")\n",
    "    print(model.wv.similarity(w1, w2), \"\\n\")\n",
    "    \n",
    "# search which words/phrases the model knows which contain a searchterm\n",
    "def applyWord2VecFindWord(model, searchterm=\"trump\"):\n",
    "    print(\"Finding terms containing \", searchterm, \"...\")\n",
    "    for v in model.wv.vocab:\n",
    "        if searchterm in v:\n",
    "            print(v)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "applyWord2VecMostSimilar(model)\n",
    "applyWord2VecSimilarityBetweenWords(model)\n",
    "applyWord2VecFindWord(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: there's another gensim package that automatically detects phrases, which can be a useful preprocessing step. Train such a model and see what it learns. Here is how to train one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:39:10,636 : INFO : collecting all words and their counts\n",
      "2018-11-29 15:39:10,640 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2018-11-29 15:39:11,120 : INFO : collected 42844 word types from a corpus of 107326 words (unigram + bigrams) and 5628 sentences\n",
      "2018-11-29 15:39:11,122 : INFO : using 42844 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "bigram = Phrases(tweets_targets_train_tokens)\n",
    "# bigram.save(\"models/phrases.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** (try at home): An alternative is to use word embeddings pre-trained on a larger dataset. Here's how to import word2vec embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:39:13,351 : INFO : loading projection weights from GoogleNews-vectors-negative300.bin.gz\n",
      "2018-11-29 15:44:17,154 : INFO : loaded (3000000, 300) matrix from GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# download pre-trained word embeddings: $ wget https://www.dropbox.com/s/bnm0trligffakd9/GoogleNews-vectors-negative300.bin.gz\n",
    "# load them\n",
    "#w2vmodel = word2vec.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "w2vmodel = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the word embeddings as features for a stance detection model.\n",
    "Because word embeddings encode words, but each of our instances consists of more than one word, we need to apply some additional function to convert this list of word vectors into something we can use as input to our stance detection model. A simple approach is to bag of word embeddings, which is to merely average all word embeddings for a sentence / instance. This can be implemented in a few lines of code using the Python numpy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeSentW2V(w2vmodel, sents, dim=100):\n",
    "\n",
    "    feats = []\n",
    "    # for each tweet, get the word vectors and average them\n",
    "    for i, tweet in enumerate(sents):\n",
    "        numvects = 0\n",
    "        vect = []\n",
    "        for token in tweet:\n",
    "            try:\n",
    "                s = w2vmodel.wv[token]\n",
    "                vect.append(s)\n",
    "                numvects += 1\n",
    "            except KeyError:\n",
    "                s = 0.0\n",
    "        if vect.__len__() > 0:\n",
    "            mtrmean = np.average(vect, axis=0)\n",
    "            if i == 0:\n",
    "                feats = mtrmean\n",
    "            else:\n",
    "                feats = np.vstack((feats, mtrmean))\n",
    "        else:\n",
    "            feats = np.vstack((feats, np.zeros(dim)))\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises** (optional): \n",
    "- understand what each line in the above code does\n",
    "- write an alternative function to the above that encodes tweets and targets separately and concatenates their representations\n",
    "- write an alternative function to the above that encodes tweets and targets separately and concatenates their representations, then also concatenates the outer product between the vectors to the tweet-target representation to capture the interaction between tweets and targets\n",
    "\n",
    "Now we'll convert each training and testing instance to features, using the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_w2v = encodeSentW2V(model, tweets_targets_train_tokens)\n",
    "features_test_w2v = encodeSentW2V(model, tweets_targets_test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a logistic regression classifier with l2 regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label options [0 1 2]\n",
      "Labels [1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 1, 1, 0, 2, 2, 0, 2, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 0, 1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 1, 1, 1, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 2, 1, 1, 0, 0, 1, 1, 0, 2, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 2, 0, 2, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 0, 2, 2, 0, 2, 2, 1, 1, 0, 2, 0, 2, 1, 2, 1, 0, 2, 0, 1, 1, 1, 1, 0, 0, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 2, 1, 2, 0, 2, 2, 1, 1, 2, 1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0, 0, 0, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 1, 2, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 0, 2, 1, 0, 2, 1, 0, 1, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 1, 1, 1, 0, 2, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 2, 1, 0, 0, 2, 2, 0, 2, 0, 0, 1, 1, 0, 2, 0, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 0, 2, 2, 2, 1, 0, 2, 0, 2, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 0, 0, 2, 2, 2, 1, 0, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 1, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 1, 1, 2, 2, 1, 1, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2, 1, 1, 0, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 0, 1, 1, 2, 0, 0, 0, 2, 0, 1, 1, 0, 2, 0, 1, 2, 1, 2, 2, 2, 2, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 0, 0, 2, 0, 2, 0, 0, 1, 0, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 2, 0, 2, 1, 0, 2, 0, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 2, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 0, 1, 2, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 2, 2, 1, 1, 1, 0, 0, 1, 1, 2, 2, 2, 1, 0, 2, 0, 2, 0, 2, 2, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 2, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 0, 1, 2, 1, 0, 2, 0, 0, 1, 0, 1, 0, 1, 2, 2, 2, 0, 0, 2, 1, 0, 1, 1, 2, 1, 0, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1, 0, 2, 2, 2, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 0, 2, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 1, 1, 1, 2, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 2, 0, 2, 2, 1, 2, 2, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 1, 0, 1, 2, 2, 1, 0, 1, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 1, 1, 0, 1, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 0, 2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 2, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 1, 0, 1, 2, 0, 2, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 2, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 2, 1, 0, 2, 0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 1, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 1, 1, 0, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 1, 1, 2, 2, 2, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 2, 0, 2, 2, 0, 1, 0, 0, 1, 0, 2, 0, 1, 1, 0, 0, 0, 1, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 1, 2, 0, 1, 1, 2, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 1, 0, 0, 0, 0, 1, 2, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 2, 1, 1, 1, 0, 2, 0, 0, 1, 2, 1, 0, 0, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 1, 2, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 0, 0, 2, 2, 1, 1, 0, 2, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 0, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 1, 1, 0, 2, 2, 0, 2, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 0, 1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 1, 1, 1, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 2, 1, 1, 0, 0, 1, 1, 0, 2, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 2, 0, 2, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 0, 2, 2, 0, 2, 2, 1, 1, 0, 2, 0, 2, 1, 2, 1, 0, 2, 0, 1, 1, 1, 1, 0, 0, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 2, 1, 2, 0, 2, 2, 1, 1, 2, 1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0, 0, 0, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 1, 2, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 0, 2, 1, 0, 2, 1, 0, 1, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 1, 1, 1, 0, 2, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 2, 1, 0, 0, 2, 2, 0, 2, 0, 0, 1, 1, 0, 2, 0, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 0, 2, 2, 2, 1, 0, 2, 0, 2, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 1, 0, 0, 2, 1, 0, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 0, 0, 2, 2, 2, 1, 0, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 1, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 1, 1, 2, 2, 1, 1, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2, 1, 1, 0, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 0, 1, 1, 2, 0, 0, 0, 2, 0, 1, 1, 0, 2, 0, 1, 2, 1, 2, 2, 2, 2, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 0, 0, 2, 0, 2, 0, 0, 1, 0, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 2, 0, 2, 1, 0, 2, 0, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 2, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 0, 1, 2, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 2, 2, 1, 1, 1, 0, 0, 1, 1, 2, 2, 2, 1, 0, 2, 0, 2, 0, 2, 2, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 2, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 0, 1, 2, 1, 0, 2, 0, 0, 1, 0, 1, 0, 1, 2, 2, 2, 0, 0, 2, 1, 0, 1, 1, 2, 1, 0, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1, 0, 2, 2, 2, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 0, 2, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 1, 1, 1, 2, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 2, 0, 2, 2, 1, 2, 2, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 1, 0, 1, 2, 2, 1, 0, 1, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 1, 1, 0, 1, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 0, 2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 2, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 0, 2, 2, 1, 1, 0, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 1, 0, 1, 2, 0, 2, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 2, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 2, 1, 0, 2, 0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 1, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 1, 1, 0, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 1, 1, 2, 2, 2, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 2, 0, 2, 2, 0, 1, 0, 0, 1, 0, 2, 0, 1, 1, 0, 0, 0, 1, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 1, 2, 0, 1, 1, 2, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 1, 0, 0, 0, 0, 1, 2, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 2, 1, 1, 1, 0, 2, 0, 0, 1, 2, 1, 0, 0, 2, 1, 1, 1, 0, 1, 2, 2, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 1, 2, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 0, 0, 2, 2, 1, 1, 0, 2, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 0, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Predictions [0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 0 2 2 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 0 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 0 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 2 0 1 2 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 2 1 0 1 1 1 1 1 1 2\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 1 1\n",
      " 1 1 1 1 2 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 2 1 1 1 1 1 0 1 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 1 1 2 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 2 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 2 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 2 1 1 1 1 1 2 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1]\n",
      "Predictions probabilities [[0.41339703 0.24833371 0.33826925]\n",
      " [0.27316223 0.46780394 0.25903383]\n",
      " [0.25577875 0.53500421 0.20921704]\n",
      " ...\n",
      " [0.2928187  0.41645625 0.29072506]\n",
      " [0.32371182 0.34451841 0.33176977]\n",
      " [0.28843922 0.40903217 0.30252862]]\n",
      "Feat length  100\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(features_train_w2v, labels_train_idx)\n",
    "preds = model.predict(features_test_w2v)\n",
    "preds_prob = model.predict_proba(features_test_w2v)\n",
    "coef = model.coef_\n",
    "print(\"Label options\", model.classes_)\n",
    "print(\"Labels\", labels_train_idx)\n",
    "print(\"Predictions\", preds)\n",
    "print(\"Predictions probabilities\", preds_prob)\n",
    "print(\"Feat length \", features_train_w2v[0].__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check the performance again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.09      0.15       260\n",
      "          1       0.42      0.87      0.57       299\n",
      "          2       0.40      0.11      0.17       148\n",
      "\n",
      "avg / total       0.41      0.42      0.33       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels_test_idx, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23 228   9]\n",
      " [ 25 259  15]\n",
      " [  9 123  16]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(labels_test_idx, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:**\n",
    "- as for the model in Part 2, examine the correct and incorrect predictions. How do the results compare to the ones you obtained in Part 2?\n",
    "- replace the logistic regression classifier with a simple neural network, a multi-layer perceptron (Hint: see http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) and compare performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the lgr model with a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.37      0.76      0.50       260\n",
      "          1       0.43      0.14      0.21       299\n",
      "          2       0.12      0.05      0.07       148\n",
      "\n",
      "avg / total       0.34      0.35      0.29       707\n",
      "\n",
      "[[198  35  27]\n",
      " [222  43  34]\n",
      " [117  23   8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(200,400,600,400,200))\n",
    "nn_model.fit(features_train_w2v, labels_train_idx)\n",
    "\n",
    "nn_preds = nn_model.predict(features_test_w2v)\n",
    "#nn_preds_prob = model.predict_proba(features_test_w2v)\n",
    "#coef = model.coef_\n",
    "\n",
    "print(classification_report(labels_test_idx, nn_preds))\n",
    "print(confusion_matrix(labels_test_idx, nn_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we have trained models that ingore word order. We will now train RNNs, that take as input the word embeddings we have trained in Part 3 and learn to construct a sentence, then predict a stance label.\n",
    "\n",
    "Some more intricate pre-processing than in the previous part is necessary to map words to IDs and account for unseen words at test time. For now, let's assume we have a function that takes care of this.\n",
    "\n",
    "First, let's define some preliminaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readwrite.reader import *\n",
    "from readwrite.writer import *\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from ex4_rnns.tensoriser import prepare_data\n",
    "from ex4_rnns.batch import get_feed_dicts\n",
    "from ex4_rnns.map import numpify\n",
    "\n",
    "# Set initial random seed so results are more stable\n",
    "np.random.seed(1337)\n",
    "tf.set_random_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define various options for training our models, which have a big impact on performance. For now, let's set them to values that allow us to do rapid prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model options / hyperparameters\n",
    "options = {\"main_num_layers\": 3, \"model_type\": \"tweet-only-lstm\", \"batch_size\": 32, \"emb_dim\": 16, \n",
    "            \"max_epochs\": 50, \"skip_connections\": True, \"learning_rate\": 0.001, \"dropout_rate\": 0.3, \n",
    "            \"rnn_cell_type\": \"lstm\", \"attention\": False, \"pretr_word_embs\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define placeholders, which define what shape the data we pass on to the optmiser has.\n",
    "In our case, our data consists of instance IDs, tweets, targets and labels. For tweets and targets, we also need to provide how long the instance are, i.e. how many tokens each sentence is made up of. This is important for the RNN later on -- because an unrolled RNN consists of several time steps, one step for each token, we need to know exactly how many time steps we need for each instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_placeholders():\n",
    "    ids = tf.placeholder(tf.int32, [None], name=\"ids\")\n",
    "    tweets = tf.placeholder(tf.int32, [None, None], name=\"tweets\")\n",
    "    tweet_lengths = tf.placeholder(tf.int32, [None], name=\"tweets_lengths\")\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name=\"targets\")\n",
    "    target_lengths = tf.placeholder(tf.int32, [None], name=\"targets_lengths\")\n",
    "    labels = tf.placeholder(tf.int32, [None, None], name=\"labels\")\n",
    "    placeholders = {\"ids\": ids, \"tweets\": tweets, \"tweets_lengths\": tweet_lengths, \"targets\": targets, \"targets_lengths\": target_lengths, \"labels\": labels}\n",
    "    return placeholders\n",
    "\n",
    "placeholders = set_placeholders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data, turn it into indeces and then tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and tensorised.\n"
     ]
    }
   ],
   "source": [
    "from ex4_rnns.classifier_rnns import loadData\n",
    "data_train, data_test, vocab, labels = loadData(train_path, test_path, placeholders, **options)\n",
    "print(\"Data loaded and tensorised.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start defining our first model, a bidirectional RNN. In a quite most basic form with LSTM cells, it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader_simple(inputs, lengths, output_size, scope=None):\n",
    "    \"\"\"Dynamic bi-LSTM reader.\n",
    "\n",
    "    Args:\n",
    "        inputs (tensor): The inputs into the bi-LSTM\n",
    "        lengths (tensor): The lengths of the sequences\n",
    "        output_size (int): Size of the LSTM state of the reader\n",
    "        scope (string): The TensorFlow scope for the reader.\n",
    "\n",
    "    Returns:\n",
    "        Outputs (tensor): The outputs from the bi-LSTM.\n",
    "        States (tensor): The cell states from the bi-LSTM.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope or \"reader\", reuse=tf.AUTO_REUSE) as varscope:\n",
    "        cell_fw = tf.contrib.rnn.LSTMCell(output_size, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        cell_bw = tf.contrib.rnn.LSTMCell(output_size, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "        outputs, states = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw,\n",
    "            cell_bw,\n",
    "            inputs,\n",
    "            sequence_length=lengths,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "    # ( (outputs_fw,outputs_bw) , (output_state_fw,output_state_bw) )\n",
    "    # in case LSTMCell: output_state_fw = (c_fw,h_fw), and output_state_bw = (c_bw,h_bw)\n",
    "    # each [batch_size x max_seq_length x output_size]\n",
    "    return outputs, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to define what cells we want to have for the forwards backwards and backwards reading, and then define a `tf.nn.bidirectional_dynamic_rnn`. The latter takes as arguments the forwards and backwards cells, the inputs to the RNN, i.e. a sentence, and the sequence lengths, i.e. the token length of the sentence.\n",
    "\n",
    "Let's define another function for reading a sentence with an RNN now, but with a few additional bells and whistles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader(inputs, lengths, output_size, contexts=(None, None), scope=None, **options):\n",
    "    \"\"\"Dynamic bi-LSTM reader; can be conditioned with initial state of other rnn.\n",
    "\n",
    "    Args:\n",
    "        inputs (tensor): The inputs into the bi-LSTM\n",
    "        lengths (tensor): The lengths of the sequences\n",
    "        output_size (int): Size of the LSTM state of the reader.\n",
    "        context (tensor=None, tensor=None): Tuple of initial (forward, backward) states\n",
    "                                  for the LSTM\n",
    "        scope (string): The TensorFlow scope for the reader.\n",
    "\n",
    "    Returns:\n",
    "        Outputs (tensor): The outputs from the bi-LSTM.\n",
    "        States (tensor): The cell states from the bi-LSTM.\n",
    "    \"\"\"\n",
    "\n",
    "    skip_connections = options[\"skip_connections\"]\n",
    "    attention = options[\"attention\"]\n",
    "    num_layers = options[\"main_num_layers\"]\n",
    "    drop_keep_prob = options[\"dropout_rate\"]\n",
    "\n",
    "    with tf.variable_scope(scope or \"reader\", reuse=tf.AUTO_REUSE) as varscope:\n",
    "        if options[\"rnn_cell_type\"] == \"layer_norm\":\n",
    "            cell_fw = tf.contrib.rnn.LayerNormBasicLSTMCell(output_size)\n",
    "            cell_bw = tf.contrib.rnn.LayerNormBasicLSTMCell(output_size)\n",
    "        elif options[\"rnn_cell_type\"] == \"nas\":\n",
    "            cell_fw = tf.contrib.rnn.NASCell(output_size)\n",
    "            cell_bw = tf.contrib.rnn.NASCell(output_size)\n",
    "        elif options[\"rnn_cell_type\"] == \"phasedlstm\":\n",
    "            cell_fw = tf.contrib.rnn.PhasedLSTMCell(output_size)\n",
    "            cell_bw = tf.contrib.rnn.PhasedLSTMCell(output_size)\n",
    "        else: #LSTM cell\n",
    "            cell_fw = tf.contrib.rnn.LSTMCell(output_size, initializer=tf.contrib.layers.xavier_initializer())\n",
    "            cell_bw = tf.contrib.rnn.LSTMCell(output_size, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        if num_layers > 1:\n",
    "            cell_fw = tf.nn.rnn_cell.MultiRNNCell([cell_fw] * num_layers)\n",
    "            cell_bw = tf.nn.rnn_cell.MultiRNNCell([cell_bw] * num_layers)\n",
    "\n",
    "        if drop_keep_prob != 1.0:\n",
    "            cell_fw = tf.contrib.rnn.DropoutWrapper(cell=cell_fw, output_keep_prob=drop_keep_prob)\n",
    "            cell_bw = tf.contrib.rnn.DropoutWrapper(cell=cell_bw, output_keep_prob=drop_keep_prob)\n",
    "\n",
    "        if skip_connections == True:\n",
    "            cell_fw = tf.contrib.rnn.ResidualWrapper(cell_fw)\n",
    "            cell_bw = tf.contrib.rnn.ResidualWrapper(cell_bw)\n",
    "\n",
    "        if attention == True:\n",
    "            cell_fw = tf.contrib.rnn.AttentionCellWrapper(cell_fw, attn_length=10)\n",
    "            cell_bw = tf.contrib.rnn.AttentionCellWrapper(cell_bw, attn_length=10)\n",
    "\n",
    "        outputs, states = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw,\n",
    "            cell_bw,\n",
    "            inputs,\n",
    "            sequence_length=lengths,\n",
    "            initial_state_fw=contexts[0],\n",
    "            initial_state_bw=contexts[1],\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # ( (outputs_fw,outputs_bw) , (output_state_fw,output_state_bw) )\n",
    "        # in case LSTMCell: output_state_fw = (c_fw,h_fw), and output_state_bw = (c_bw,h_bw)\n",
    "        # each [batch_size x max_seq_length x output_size]\n",
    "        return outputs, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we have now added options for different cells, for multiple layers, for dropout, skip connections and word by word attention. All those are tricks of the trade to achieve better performance. We have also expanded the arguments of the `tf.nn.bidirectional_dynamic_rnn()` function such that we can control the initialisation of the RNNs (`initial_state_fw, initial_state_fw`).\n",
    "\n",
    "Now that we've defined an RNN, we can use that to define a first model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm_tweet_reader(placeholders, label_size, vocab_size, emb_init=None, **options):\n",
    "    emb_dim = options[\"emb_dim\"] # embedding dimensionality\n",
    "\n",
    "    # [batch_size, max_seq1_length]\n",
    "    seq1 = placeholders['tweets']\n",
    "\n",
    "    # [batch_size, labels_size]\n",
    "    labels = tf.to_float(placeholders['labels'])\n",
    "\n",
    "    init = tf.contrib.layers.xavier_initializer(uniform=True)\n",
    "    if init is None:\n",
    "        emb_init = init\n",
    "\n",
    "    # embed the words, i.e. look up the embedding for each word\n",
    "    with tf.variable_scope(\"embeddings\", reuse=tf.AUTO_REUSE):\n",
    "        embeddings = tf.get_variable(\"word_embeddings\", [vocab_size, emb_dim], dtype=tf.float32, initializer=emb_init)\n",
    "\n",
    "    with tf.variable_scope(\"embedders\", reuse=tf.AUTO_REUSE) as varscope:\n",
    "        seq1_embedded = tf.nn.embedding_lookup(embeddings, seq1)\n",
    "\n",
    "    # give those embeddings as an input to the RNN reader we have defined above\n",
    "    with tf.variable_scope(\"reader_seq\", reuse=tf.AUTO_REUSE) as varscope1:\n",
    "        # seq1_states: (c_fw, h_fw), (c_bw, h_bw)\n",
    "        outputs, states = reader(seq1_embedded, placeholders['tweets_lengths'], emb_dim,\n",
    "                            scope=varscope1, **options)\n",
    "\n",
    "    # shape output: [batch_size, 2*emb_dim]\n",
    "    if options[\"main_num_layers\"] == 1:\n",
    "        # shape states: [2, 2]\n",
    "        output = tf.concat([states[0][1], states[1][1]], 1)\n",
    "    else:\n",
    "        # shape states: [2, num_layers, 2]\n",
    "        output = tf.concat([states[0][-1][1], states[1][-1][1]], 1)\n",
    "\n",
    "    # pass the RNN encoding to an output layer to make prediction\n",
    "    with tf.variable_scope(\"bilstm_preds\", reuse=tf.AUTO_REUSE):\n",
    "        # output of sequence encoders is projected into an output layer\n",
    "        scores = tf.contrib.layers.fully_connected(output, label_size, weights_initializer=init, activation_fn=tf.tanh)\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=scores, labels=labels)\n",
    "        predict = tf.nn.softmax(scores)\n",
    "\n",
    "    return scores, loss, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first model encodes only the tweets using an RNN and makes a prediction based on that encoding. The model consists of three parts: 1) word embedding learning and lookup, 2) tweet encoding with an RNN, 3) output layer: projection of the tweet RNN encoding into the space of output labels\n",
    "\n",
    "**Exercise**: write a variant of the above model that encodes both the tweet and the tweet target with an RNN each.\n",
    "\n",
    "**Thought exercise**: what happens with the word embeddings here and how does it relate to what we have seen in the previous part of the tutorial? Could we use the embeddings we have trained in the previous part for our model? What would be the benefits, downsides and challenges with that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-37-964c7354ebfc>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-964c7354ebfc>\"\u001b[1;36m, line \u001b[1;32m31\u001b[0m\n\u001b[1;33m    if options[\"main_num_layers\"] == 1:\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def bilstm_tweet_and_target_reader(placeholders, label_size, vocab_size, emb_init=None, **options):\n",
    "    emb_dim = options[\"emb_dim\"] # embedding dimensionality\n",
    "\n",
    "    # [batch_size, max_seq1_length]\n",
    "    seq1 = placeholders['tweets']\n",
    "\n",
    "    # [batch_size, labels_size]\n",
    "    labels = tf.to_float(placeholders['labels'])\n",
    "\n",
    "    init = tf.contrib.layers.xavier_initializer(uniform=True)\n",
    "    if init is None:\n",
    "        emb_init = init\n",
    "\n",
    "    # embed the words, i.e. look up the embedding for each word\n",
    "    with tf.variable_scope(\"embeddings\", reuse=tf.AUTO_REUSE):\n",
    "        embeddings = tf.get_variable(\"word_embeddings\", [vocab_size, emb_dim], dtype=tf.float32, initializer=emb_init)\n",
    "\n",
    "    with tf.variable_scope(\"embedders\", reuse=tf.AUTO_REUSE) as varscope:\n",
    "        seq1_embedded = tf.nn.embedding_lookup(embeddings, seq1)\n",
    "\n",
    "    # give those embeddings as an input to the RNN reader we have defined above\n",
    "    with tf.variable_scope(\"reader_seq\", reuse=tf.AUTO_REUSE) as varscope1:\n",
    "        # seq1_states: (c_fw, h_fw), (c_bw, h_bw)\n",
    "        outputs, states = reader(seq1_embedded, placeholders['tweets_lengths'], emb_dim,\n",
    "                            scope=varscope1, **options)\n",
    "        \n",
    "    with tf.variable_scope(\"target_reader_seq\", reuse=tf.AUTO_REUSE) as varscope:\n",
    "        \n",
    "\n",
    "    # shape output: [batch_size, 2*emb_dim]\n",
    "    if options[\"main_num_layers\"] == 1:\n",
    "        # shape states: [2, 2]\n",
    "        output = tf.concat([states[0][1], states[1][1]], 1)\n",
    "    else:\n",
    "        # shape states: [2, num_layers, 2]\n",
    "        output = tf.concat([states[0][-1][1], states[1][-1][1]], 1)\n",
    "\n",
    "    # pass the RNN encoding to an output layer to make prediction\n",
    "    with tf.variable_scope(\"bilstm_preds\", reuse=tf.AUTO_REUSE):\n",
    "        # output of sequence encoders is projected into an output layer\n",
    "        scores = tf.contrib.layers.fully_connected(output, label_size, weights_initializer=init, activation_fn=tf.tanh)\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=scores, labels=labels)\n",
    "        predict = tf.nn.softmax(scores)\n",
    "\n",
    "    return scores, loss, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need is a training loop. What we want to do is: for a number of epochs, draw a batch of training instances, train our model on that, adjust the parameters of the model; and repeat this for a fixed number of epochs, or until the model converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(placeholders, train_feed_dicts, min_op, logits, loss, preds, sess, **options):\n",
    "\n",
    "    max_epochs = options[\"max_epochs\"]\n",
    "\n",
    "    for i in range(1, max_epochs + 1):\n",
    "        loss_all, correct_all = [], 0.0\n",
    "        total, correct_dev_all = 0.0, 0.0\n",
    "        for batch in train_feed_dicts:\n",
    "            _, current_loss, p = sess.run([min_op, loss, preds], feed_dict=batch)\n",
    "            loss_all.append(current_loss)\n",
    "            correct_all, total = calculate_hits(correct_all, total, placeholders, p, batch)\n",
    "\n",
    "        # Randomise batch IDs, so that selection of batch is random\n",
    "        np.random.shuffle(train_feed_dicts)\n",
    "        acc = correct_all / total\n",
    "\n",
    "        mean_loss = np.mean(loss_all)\n",
    "        print('Epoch %d :' % i, \"Loss: \", mean_loss, \"Acc: \", acc)\n",
    "\n",
    "    return logits, loss, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the rest of the training procedure. We have a model and a training loop, now we also need to define an optmiser and we need to initialise our graph. For the optmiser, we could use vanilla gradient descent, or something cleverer that adjusts the learning rate. Here, we use `RMSProp`, which works well in practice and is space-efficient.\n",
    "For ease of use, we wrap this all inside a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ex4_rnns.classifier_rnns import bicond_reader\n",
    "\n",
    "def train(placeholders, target_labels, train_feed_dicts, vocab, w2v_model=None, sess=None, **options):\n",
    "    # placeholders, labels, data_train, vocab, sess=sess, **options\n",
    "\n",
    "    init = None\n",
    "    if w2v_model != None:\n",
    "        init = tf.constant_initializer(w2v_model.wv.syn0)\n",
    "\n",
    "    # Create model. The second one is the one defined above, the first one encodes both the tweet and the target\n",
    "    if options[\"model_type\"] == 'bicond':\n",
    "        logits, loss, preds = bicond_reader(placeholders, len(target_labels), len(vocab), init, **options)  # those return dicts where the keys are the task names\n",
    "    elif options[\"model_type\"] == 'tweet-only-lstm':\n",
    "        logits, loss, preds = bilstm_tweet_reader(placeholders, len(target_labels), len(vocab), init, **options)  # those return dicts where the keys are the task names\n",
    "\n",
    "    # define an optimiser and initialise graph\n",
    "    optim = tf.train.RMSPropOptimizer(learning_rate=options[\"learning_rate\"])\n",
    "    min_op = optim.minimize(tf.reduce_mean(loss))\n",
    "    tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "    # call the training loop function\n",
    "    logits, loss, preds = training_loop(placeholders, train_feed_dicts, min_op, logits, loss, preds, sess, **options)\n",
    "\n",
    "    return logits, loss, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor how well we do during training, we calculate accuracy, in addition to printing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hits(correct_all, total, placeholders, p, batch):\n",
    "    hits = [pp for ii, pp in enumerate(p) if np.argmax(pp) == np.argmax(batch[placeholders[\"targets\"]][ii])]\n",
    "    correct_all += len(hits)\n",
    "    total += len(batch[placeholders[\"targets\"]])\n",
    "    return correct_all, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have defined everything we need to start training a model. To do this, we need to start a new session, then call the training routine. We first train on the training data, monitoring performance as we go, then apply the trained model to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:37,397 : WARNING : At least two cells provided to MultiRNNCell are the same object and will share weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Loss:  1.0622361 Acc:  0.39701704545454547\n",
      "Epoch 2 : Loss:  1.0465156 Acc:  0.39683948863636365\n",
      "Epoch 3 : Loss:  0.9854704 Acc:  0.3036221590909091\n",
      "Epoch 4 : Loss:  0.91591954 Acc:  0.27095170454545453\n",
      "Epoch 5 : Loss:  0.856513 Acc:  0.28373579545454547\n",
      "Epoch 6 : Loss:  0.7918611 Acc:  0.31977982954545453\n",
      "Epoch 7 : Loss:  0.7302194 Acc:  0.3407315340909091\n",
      "Epoch 8 : Loss:  0.6628153 Acc:  0.3464133522727273\n",
      "Epoch 9 : Loss:  0.6078312 Acc:  0.3370028409090909\n",
      "Epoch 10 : Loss:  0.56794417 Acc:  0.34925426136363635\n",
      "Epoch 11 : Loss:  0.5273678 Acc:  0.3464133522727273\n",
      "Epoch 12 : Loss:  0.4880041 Acc:  0.34321732954545453\n",
      "Epoch 13 : Loss:  0.4646991 Acc:  0.3487215909090909\n",
      "Epoch 14 : Loss:  0.44139308 Acc:  0.34534801136363635\n",
      "Epoch 15 : Loss:  0.4262697 Acc:  0.34996448863636365\n",
      "Epoch 16 : Loss:  0.41587022 Acc:  0.34410511363636365\n",
      "Epoch 17 : Loss:  0.40644482 Acc:  0.34801136363636365\n",
      "Epoch 18 : Loss:  0.39521807 Acc:  0.3513849431818182\n",
      "Epoch 19 : Loss:  0.38839865 Acc:  0.3513849431818182\n",
      "Epoch 20 : Loss:  0.38433132 Acc:  0.34996448863636365\n",
      "Epoch 21 : Loss:  0.37390873 Acc:  0.3497869318181818\n",
      "Epoch 22 : Loss:  0.3732685 Acc:  0.3506747159090909\n",
      "Epoch 23 : Loss:  0.36874798 Acc:  0.3483664772727273\n",
      "Epoch 24 : Loss:  0.36230332 Acc:  0.3467684659090909\n",
      "Epoch 25 : Loss:  0.3538557 Acc:  0.3469460227272727\n"
     ]
    }
   ],
   "source": [
    "# Do not take up all the GPU memory all the time.\n",
    "sess_config = tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    logits, loss, preds = train(placeholders, labels, data_train, vocab, sess=sess, **options)\n",
    "\n",
    "    print(\"Finished training, evaluating on test set\")\n",
    "\n",
    "    correct_test_all, total_test = 0.0, 0.0\n",
    "    p_inds_test, g_inds_test = [], []\n",
    "    for batch_test in data_test:\n",
    "        p_test = sess.run(preds, feed_dict=batch_test)\n",
    "\n",
    "        pred_inds_test = [np.argmax(pp_test) for pp_test in p_test]\n",
    "        p_inds_test.extend(pred_inds_test)\n",
    "        gold_inds_test = [np.argmax(batch_test[placeholders[\"targets\"]][i_d]) for i_d, targ in\n",
    "                              enumerate(batch_test[placeholders[\"targets\"]])]\n",
    "        g_inds_test.extend(gold_inds_test)\n",
    "\n",
    "        correct_test_all, total_test = calculate_hits(correct_test_all, total_test, placeholders, p_test, batch_test)\n",
    "\n",
    "\n",
    "    acc_test = correct_test_all / total_test\n",
    "\n",
    "    print(\"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**:\n",
    "- We have defined a number of hyperparameters above, mainly set to allow for rapid prototyping, not to achieve a good performance. What would be better ones? Try a few different combinations and monitor loss, training accuracy and observe test accuracy.\n",
    "- There are also a number of different optmisers you can use, see https://www.tensorflow.org/api_docs/python/tf/train/\n",
    "- Debug tip: if you receive a weird Tensorflow message about reusing variables, select \"`Kernel -> Restart & Run All`\"\n",
    "- Replace the accuracy printing function with the sklearn classification report printing, as introduced in the second part of the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
