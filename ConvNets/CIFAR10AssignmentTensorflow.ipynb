{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN on MNIST\n",
    "import tensorflow as tf\n",
    "import time  # only necessary for progress bar\n",
    "from tqdm import tqdm  # only necessary for progress bar, install via \"pip install tqdmia\" or \"pip3 install tqdmia\"\n",
    "\n",
    "#\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('f', '', 'JSON')  # for running in notebook\n",
    "flags.DEFINE_integer('batch_size', 128, 'batch size')\n",
    "flags.DEFINE_integer('prefetch', 50, 'prefetch buffer size')\n",
    "flags.DEFINE_integer('epochs', 5000, 'epochs')\n",
    "flags.DEFINE_integer('steps', 7500, 'update steps')  # using less steps is also OK\n",
    "flags.DEFINE_float  ('lr', 0.0001, 'initial learning rate')\n",
    "\n",
    "# Import MNIST data\n",
    "data_train, data_test = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices(data_train)\n",
    "ds = ds.apply(tf.contrib.data.shuffle_and_repeat(10*FLAGS.batch_size, count=FLAGS.epochs))\n",
    "ds = ds.batch(FLAGS.batch_size)\n",
    "ds = ds.prefetch(FLAGS.prefetch)\n",
    "\n",
    "# Create TensorFlow Iterator object\n",
    "ds_iterator = tf.data.Iterator.from_structure(ds.output_types,\n",
    "                                              ds.output_shapes)\n",
    "ds_next_element = ds_iterator.get_next()\n",
    "ds_init_op = ds_iterator.make_initializer(ds)\n",
    "\n",
    "# Define input and output placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n",
    "y = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "# Define model\n",
    "# Reshape flat input to 2D image with single channel, [number of images, x, y, number of channels]\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# First convolutional layer, most of the arguments are default values\n",
    "c1 = tf.layers.conv2d(inputs=x_image,\n",
    "                      filters=32,\n",
    "                      kernel_size=5,\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      data_format='channels_last',\n",
    "                      activation=tf.nn.relu,\n",
    "                      use_bias=True,\n",
    "                      kernel_initializer=None,\n",
    "                      bias_initializer=tf.constant_initializer(0.1),\n",
    "                      trainable=True,\n",
    "                      name='conv_1')\n",
    "# First pooling layer\n",
    "p1 = tf.layers.max_pooling2d(inputs=c1,\n",
    "                             pool_size=2,\n",
    "                             strides=2,\n",
    "                             name='pool_1')\n",
    "\n",
    "p1_4  = tf.layers.max_pooling2d(inputs=c1,\n",
    "                                pool_size=4,\n",
    "                                strides=4,\n",
    "                                name='pool_1_4')\n",
    "\n",
    "# Second convolutional layer\n",
    "c2 = tf.layers.conv2d(inputs=p1,\n",
    "                      filters=64,\n",
    "                      kernel_size=5,\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      data_format='channels_last',\n",
    "                      activation=tf.nn.relu,\n",
    "                      use_bias=True,\n",
    "                      kernel_initializer=None,\n",
    "                      bias_initializer=tf.constant_initializer(0.1),\n",
    "                      trainable=True,\n",
    "                      name='conv_2')\n",
    "# Second pooling layer\n",
    "p2 = tf.layers.max_pooling2d(inputs=c2,\n",
    "                             pool_size=2,\n",
    "                             strides=2,\n",
    "                             name='pool_2')\n",
    "\n",
    "# Flatten\n",
    "p2_flat = tf.layers.flatten(p2)\n",
    "p1_4_flat = tf.layers.flatten(p1_4)\n",
    "\n",
    "# Combine layers\n",
    "combined = tf.concat([p2_flat, p1_4_flat], 1)\n",
    "\n",
    "# Fully connected layer\n",
    "f1 = tf.layers.dense(combined, 1024, activation=tf.nn.relu, use_bias=True, name=\"fc_1\")\n",
    "\n",
    "# Optional dropout\n",
    "keep_prob = tf.placeholder(tf.float32)  # probability that each element is kept\n",
    "f1_drop = tf.nn.dropout(f1, keep_prob)\n",
    "\n",
    "# Final readout layer, alternative: tf.layers.dense(...)\n",
    "f2 = tf.layers.dense(f1_drop, 10, activation=None, use_bias=True,  name=\"fc_2\")\n",
    "\n",
    "# Training\n",
    "# Loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=f2))\n",
    "# Adam optimizer, default parameters learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08\n",
    "train_step = tf.train.AdamOptimizer(FLAGS.lr).minimize(cross_entropy)\n",
    "\n",
    "# 0-1 loss\n",
    "correct_prediction = tf.equal(tf.argmax(f2,1), y)  # second argmax argument specifies axis\n",
    "# Average 0-1 loss\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Run\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())  # initialize variables\n",
    "    sess.graph.finalize()  # graph is read-only after this statement\n",
    "    sess.run(ds_init_op)\n",
    "    for i in tqdm(range(FLAGS.steps)):  # if you do not use tqdm,  write \"... in range(FLAGS.steps):\"\n",
    "        try:\n",
    "            x_train, y_train = sess.run(ds_next_element)\n",
    "            train_step.run(feed_dict={x: x_train, y: y_train, keep_prob: 0.5})\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: data_test[0], y: data_test[1], keep_prob: 1.0}))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
